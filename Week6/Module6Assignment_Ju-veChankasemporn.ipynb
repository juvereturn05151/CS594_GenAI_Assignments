{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# BibleAssistant\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Literal, Optional, Dict, Any, Tuple\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 1000  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 100  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 10 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5-nano\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "BIBLE_BOOKS = [\n",
        "    \"Old Testament\",\n",
        "    \"New Testament\",\n",
        "]\n",
        "\n",
        "ISSUE_QUESTIONS_CATEGORIES = [\n",
        "    \"anxiety\", \"fear\", \"grief\", \"guilt\", \"anger\", \"loneliness\",\n",
        "    \"guidance\", \"forgiveness\", \"burnout\", \"temptation\", \"question\"\n",
        "]\n",
        "\n",
        "SEVERITY_LEVELS = [\"mild\", \"moderate\", \"severe\", \"crisis\"]\n",
        "\n",
        "# How often we generate each severity (crisis is rarer)\n",
        "SEVERITY_WEIGHTS = [0.35, 0.35, 0.22, 0.08]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "class BibleExplanation(BaseModel):\n",
        "    issue_question: str\n",
        "    verse: str\n",
        "    explanation: str\n",
        "    guidance: List[str] = Field(default_factory=list)\n",
        "    note: str\n",
        "\n",
        "class BibleConversation(BaseModel):\n",
        "    user: str\n",
        "    assistant: BibleExplanation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6fd261",
      "metadata": {
        "id": "bc6fd261"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str) -> Optional[BibleConversation]:\n",
        "    try:\n",
        "        response = client.responses.parse(\n",
        "            model=DATAGEN_MODEL,\n",
        "            input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=TEMPERATURE,\n",
        "            stream=False,\n",
        "            text_format=BibleConversation,\n",
        "        )\n",
        "        return response.output_parsed\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def create_conversation(issue_question: str, severity: str) -> Optional[BibleConversation]:\n",
        "\n",
        "    if(issue_question == \"question\"):\n",
        "      request = f\"Provide a  Bible verse about {issue_question}, and explain the mearning.\"\n",
        "    else:\n",
        "      if severity == \"mild\":\n",
        "          request = f\"Provide a  Bible verse about {issue_question}, with brief encouragement (1–2 sentences each).\"\n",
        "      elif severity == \"moderate\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, each with short meaning explanations and 3–4 practical guidance steps.\"\n",
        "      elif severity == \"severe\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with deeper explanations and 4–6 compassionate guidance steps. Include strong reassurance.\"\n",
        "      elif severity == \"crisis\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with careful, supportive explanations. Include clear encouragement to seek immediate help from trusted people or local emergency services if the person is in danger.\"\n",
        "      else:\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with short explanations and practical encouragement.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Create a realistic conversation from {request}.\n",
        "\n",
        "    Context:\n",
        "    - Topic: {issue_question}\n",
        "    - Severity: {severity}\n",
        "\n",
        "    Rules:\n",
        "    - Use ONLY books from this list:\n",
        "    {\", \".join(BIBLE_BOOKS)}\n",
        "    - Verse references must be: \"Book Chapter:Verse\" or \"Book Chapter:Verse-Verse\"\n",
        "    - Do NOT cite any book outside the allowed list\n",
        "\n",
        "    Return the following if {issue_question} is \"question\":\n",
        "    1. 1–3 sentences written as the user describing their situation about {issue_question} in your own word as a string.\n",
        "    2. The single Bible selected verse and its content as a single string.\n",
        "    3. One paragraphs in one string explaining how the verses address the issue.\n",
        "\n",
        "    Return the following if {issue_question} is not \"question\":\n",
        "    1. 1–3 sentences written as the user describing their situation about {issue_question} in your own word as a string.\n",
        "    2. The single Bible selected verse and its content as a single string.\n",
        "    3. One paragraphs in one string explaining how the verses address the issue.\n",
        "    4. 1–6 short practical action steps\n",
        "    5. Short compassionate closing note. If severity is crisis, encourage contacting trusted people or emergency services.\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def generate_dataset_files(num_examples: int, jsonl_path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(jsonl_path), exist_ok=True)\n",
        "\n",
        "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
        "        for idx in tqdm(range(num_examples)):\n",
        "            issue = random.choice(ISSUE_QUESTIONS_CATEGORIES)\n",
        "            severity = random.choices(SEVERITY_LEVELS, weights=SEVERITY_WEIGHTS)[0]\n",
        "\n",
        "            conv = None\n",
        "            tries = 0\n",
        "            while conv is None and tries < 6:\n",
        "                conv = create_conversation(issue, severity)\n",
        "                tries += 1\n",
        "\n",
        "            if conv is None:\n",
        "                print(f\"Error generating conversation for example {idx}\")\n",
        "                continue\n",
        "\n",
        "            template = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": conv.user},\n",
        "                    {\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": json.dumps(conv.assistant.model_dump(), ensure_ascii=False),\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            f_jsonl.write(json.dumps(template, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc06c35",
        "outputId": "76a5b11a-3f04-44c5-c817-2730eeb6cfb2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 232/1000 [4:03:24<25:51:19, 121.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 331/1000 [5:33:15<20:46:49, 111.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 330\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 379/1000 [6:19:47<18:45:34, 108.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 378\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 437/1000 [7:12:24<15:44:21, 100.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [15:02:54<00:00, 54.17s/it]\n",
            " 95%|█████████▌| 95/100 [1:19:36<10:00, 120.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating conversation for example 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [1:24:00<00:00, 50.40s/it]\n",
            "100%|██████████| 10/10 [08:09<00:00, 48.98s/it]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "\n",
        "generate_dataset_files(NUM_TRAIN_EXAMPLES, TRAIN_FILE)\n",
        "generate_dataset_files(NUM_VAL_EXAMPLES, VALID_FILE)\n",
        "generate_dataset_files(NUM_TEST_EXAMPLES, TEST_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What use case you chose and why?\n",
        "In this world, people suffer from many issues in their lives. Therefore, I would like to create a Bible assistant that can answer people's questions about the Bible and help them feel better. I believe the Bible has the ability to heal everyone in the world. The reason I want to create this Bible AI assistant is that it can help answer the questions in people's hearts right away, without making them wait."
      ],
      "metadata": {
        "id": "MD-zzmTFyaQB"
      },
      "id": "MD-zzmTFyaQB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your diversity dimensions and how they shape the dataset\n",
        "\n",
        "For the diversity dimension, I limited the Bible books to the Old and New Testaments because they are widely accepted Christian scriptures around the world. I want to ensure that users are protected from false teachings or misleading interpretations that may come from cult sources on the internet.\n",
        "\n",
        "Regarding input, I expect users to either ask a question about the Bible or share a personal issue they are facing. For the output, the system should first restate the user’s concern in its own words to show understanding. Then it should select an appropriate verse, explain its meaning in clear and simple language—since many verses can be difficult to understand—and provide practical guidance on what the user can do. Finally, it should include a short compassionate note to make the response feel warm and caring.\n",
        "\n",
        "With this diversity dimension, users will feel as though they are consulting with a sincere and thoughtful Christian."
      ],
      "metadata": {
        "id": "eNqbn8NszpZ4"
      },
      "id": "eNqbn8NszpZ4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations from your quality review (what looked good, what needed fixing)"
      ],
      "metadata": {
        "id": "Ygsz8TENzvzN"
      },
      "id": "Ygsz8TENzvzN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample"
      ],
      "metadata": {
        "id": "VPgPjctl5YhY"
      },
      "id": "VPgPjctl5YhY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\"messages\":\n",
        "[\n",
        "  {\"role\": \"user\", \"content\": \"I've been hurt by someone who betrayed my trust, and I'm trying to forgive and move forward. I'm seeking guidance and peace rather than staying in anger.\"},\n",
        "  \n",
        "  {\"role\": \"assistant\", \"content\": \"{\n",
        "    \\\"issue_question\\\": \\\"I've been hurt by someone who betrayed my trust, and I'm trying to forgive and move forward. I'm seeking guidance and peace rather than staying in anger.\\\",\n",
        "\n",
        "   \\\"verse\\\": \\\"Matthew 6:14-15 - For if ye forgive men their trespasses, your heavenly Father will forgive you: But if ye forgive not men their trespasses, neither will your Father forgive your trespasses.\\\",\n",
        "   \n",
        "   \\\"explanation\\\": \\\"These verses teach that forgiveness is a choice we make, not merely a feeling that comes and goes. By choosing to forgive, we align with God’s mercy and open ourselves to healing, even when hurt remains. The passage also cautions that withholding forgiveness can hinder our own experience of divine mercy, reminding us that mercy towards others is connected to mercy received.\\\",\n",
        "   \n",
        "   \\\"guidance\\\": [\\\"Take a moment to acknowledge the hurt and name what you want to release.\\\", \\\"Ask God for the strength to forgive and release bitterness.\\\", \\\"Choose to forgive in your heart today, even if emotions linger.\\\", \\\"If safe and possible, speak with the person about forgiveness in a calm, boundaries-respecting way.\\\", \\\"Journal or pray daily about your progress and seek support from a trusted friend or counselor.\\\"],\n",
        "   \n",
        "   \\\"note\\\": \\\"Be gentle with yourself—forgiveness is a process, and progress may be gradual.\\\"}\"}\n",
        "   ]\n",
        "   }"
      ],
      "metadata": {
        "id": "_TajyzEn49qm"
      },
      "id": "_TajyzEn49qm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What Looked Good?"
      ],
      "metadata": {
        "id": "civdRLTo5dzj"
      },
      "id": "civdRLTo5dzj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think it looks good so far, it actually feels like what I would expect when consulting with a Christian"
      ],
      "metadata": {
        "id": "ez85ZrDL5gDH"
      },
      "id": "ez85ZrDL5gDH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What Needed Fixing?"
      ],
      "metadata": {
        "id": "ADsCzCod56w2"
      },
      "id": "ADsCzCod56w2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having the agent stating the issue feel unnecessary. It doesn't speak in their own word as I expected, but it's fine"
      ],
      "metadata": {
        "id": "Vw3IaERJ56t2"
      },
      "id": "Vw3IaERJ56t2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson Learned"
      ],
      "metadata": {
        "id": "Hz8W1Gxl6KVY"
      },
      "id": "Hz8W1Gxl6KVY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I initially tried training a fighting game helper model, but it generated unusable data. I think this happened because fighting games are a niche topic and require highly specific knowledge. Most of that knowledge is found in YouTube tutorial videos rather than structured text sources.\n",
        "\n",
        "In contrast, the Bible is a widely known and well-documented topic with abundant written material available. That is likely why this approach works much better for the Bible-based assistant."
      ],
      "metadata": {
        "id": "zQk-DfBJ6gM_"
      },
      "id": "zQk-DfBJ6gM_"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}