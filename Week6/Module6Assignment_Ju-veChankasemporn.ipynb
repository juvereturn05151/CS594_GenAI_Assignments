{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# Generate Synthetic Training Data\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN_EXAMPLES = 8000  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 1000  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 100 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5.2-codex\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "TOPICS = [\n",
        "    \"Strings\",\n",
        "    \"input()\",\n",
        "    \"print()\",\n",
        "    \"Creating variables\",\n",
        "    \"Concatenating strings\"\n",
        "    \"Lists\",\n",
        "    \"if/else constructs\",\n",
        "    \"in operator\",\n",
        "    \"list methods: append and remove\",\n",
        "    \"list methods: index, pop, and insert\",\n",
        "    \"list methods: slicing\",\n",
        "    \"list methods: deleting an item\",\n",
        "    \"for loops\",\n",
        "    \"range() and str()\",\n",
        "    \"== comparison operator\",\n",
        "    \"len() function\",\n",
        "    \"code commenting with #\",\n",
        "    \"Comparison operators: !=, >, >=, <, <=\",\n",
        "    \"String methods: .lower(), .upper(), .title(), .capitalize()\",\n",
        "    \"Using the newline character in strings\",\n",
        "    \"int()\",\n",
        "    \"float()\",\n",
        "    \"elif\",\n",
        "    \"import keyword\",\n",
        "    \"random module\",\n",
        "    \"while keyword\",\n",
        "    \"or and not operators\",\n",
        "    \"booleans\",\n",
        "    \"list methods: .clear(), .copy(), .count(), .extend(), .reverse(), .sort()\",\n",
        "    \"Dictionaries\",\n",
        "    \"Dictionary methods: .items(), .keys(), .values(), .update(), .pop()\",\n",
        "    \"Dictonary methods: .get(), .format()\",\n",
        "    \"String methods: .find(), .join(), .replace(), .split(), .swapcase()\",\n",
        "    \"Functions: using def and return keywords\",\n",
        "    \"Function methods: .isinstance()\",\n",
        "    \"Raising exceptions\",\n",
        "    \"Exceptions: TypeError() and ValueError()\",\n",
        "    \"Function keywords: as and from\",\n",
        "    \"The sys module\",\n",
        "    \"The with keyword\",\n",
        "    \"Tuples\",\n",
        "    \"The lambda keyword\",\n",
        "    \"The built-in map function\",\n",
        "    \"The time module\",\n",
        "    \"Built in methods: __init()__ and __str()__\",\n",
        "    \"Double underscore for private methods\",\n",
        "    \"Classes\"\n",
        "]\n",
        "\n",
        "CODE_LENGTH = [\n",
        "    \"short\",\n",
        "    \"paragraph\",\n",
        "    \"small_function\",\n",
        "    \"large_function\",\n",
        "]\n",
        "CODE_LENGTH_WEIGHTS = [0.25, 0.25, 0.25, 0.25]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class CodeExplanation(BaseModel):\n",
        "    code: str\n",
        "    explanation: str"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "bc6fd261",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6fd261",
        "outputId": "f50b1588-3f13-4af3-b373-0f4c79140570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google/gemini-3.1-pro-preview\n",
            "anthropic/claude-sonnet-4.6\n",
            "qwen/qwen3.5-plus-02-15\n",
            "qwen/qwen3.5-397b-a17b\n",
            "minimax/minimax-m2.5\n",
            "z-ai/glm-5\n",
            "qwen/qwen3-max-thinking\n",
            "anthropic/claude-opus-4.6\n",
            "qwen/qwen3-coder-next\n",
            "openrouter/free\n",
            "stepfun/step-3.5-flash:free\n",
            "stepfun/step-3.5-flash\n",
            "arcee-ai/trinity-large-preview:free\n",
            "moonshotai/kimi-k2.5\n",
            "upstage/solar-pro-3:free\n",
            "minimax/minimax-m2-her\n",
            "writer/palmyra-x5\n",
            "liquid/lfm-2.5-1.2b-thinking:free\n",
            "liquid/lfm-2.5-1.2b-instruct:free\n",
            "openai/gpt-audio\n",
            "openai/gpt-audio-mini\n",
            "z-ai/glm-4.7-flash\n",
            "openai/gpt-5.2-codex\n",
            "allenai/molmo-2-8b\n",
            "allenai/olmo-3.1-32b-instruct\n",
            "bytedance-seed/seed-1.6-flash\n",
            "bytedance-seed/seed-1.6\n",
            "minimax/minimax-m2.1\n",
            "z-ai/glm-4.7\n",
            "google/gemini-3-flash-preview\n",
            "mistralai/mistral-small-creative\n",
            "allenai/olmo-3.1-32b-think\n",
            "xiaomi/mimo-v2-flash\n",
            "nvidia/nemotron-3-nano-30b-a3b:free\n",
            "nvidia/nemotron-3-nano-30b-a3b\n",
            "openai/gpt-5.2-chat\n",
            "openai/gpt-5.2-pro\n",
            "openai/gpt-5.2\n",
            "mistralai/devstral-2512\n",
            "relace/relace-search\n",
            "z-ai/glm-4.6v\n",
            "nex-agi/deepseek-v3.1-nex-n1\n",
            "essentialai/rnj-1-instruct\n",
            "openrouter/bodybuilder\n",
            "openai/gpt-5.1-codex-max\n",
            "amazon/nova-2-lite-v1\n",
            "mistralai/ministral-14b-2512\n",
            "mistralai/ministral-8b-2512\n",
            "mistralai/ministral-3b-2512\n",
            "mistralai/mistral-large-2512\n",
            "arcee-ai/trinity-mini:free\n",
            "arcee-ai/trinity-mini\n",
            "deepseek/deepseek-v3.2-speciale\n",
            "deepseek/deepseek-v3.2\n",
            "prime-intellect/intellect-3\n",
            "anthropic/claude-opus-4.5\n",
            "allenai/olmo-3-32b-think\n",
            "allenai/olmo-3-7b-instruct\n",
            "allenai/olmo-3-7b-think\n",
            "google/gemini-3-pro-image-preview\n",
            "x-ai/grok-4.1-fast\n",
            "google/gemini-3-pro-preview\n",
            "deepcogito/cogito-v2.1-671b\n",
            "openai/gpt-5.1\n",
            "openai/gpt-5.1-chat\n",
            "openai/gpt-5.1-codex\n",
            "openai/gpt-5.1-codex-mini\n",
            "kwaipilot/kat-coder-pro\n",
            "moonshotai/kimi-k2-thinking\n",
            "amazon/nova-premier-v1\n",
            "perplexity/sonar-pro-search\n",
            "mistralai/voxtral-small-24b-2507\n",
            "openai/gpt-oss-safeguard-20b\n",
            "nvidia/nemotron-nano-12b-v2-vl:free\n",
            "nvidia/nemotron-nano-12b-v2-vl\n",
            "minimax/minimax-m2\n",
            "qwen/qwen3-vl-32b-instruct\n",
            "liquid/lfm2-8b-a1b\n",
            "liquid/lfm-2.2-6b\n",
            "ibm-granite/granite-4.0-h-micro\n",
            "openai/gpt-5-image-mini\n",
            "anthropic/claude-haiku-4.5\n",
            "qwen/qwen3-vl-8b-thinking\n",
            "qwen/qwen3-vl-8b-instruct\n",
            "openai/gpt-5-image\n",
            "openai/o3-deep-research\n",
            "openai/o4-mini-deep-research\n",
            "nvidia/llama-3.3-nemotron-super-49b-v1.5\n",
            "baidu/ernie-4.5-21b-a3b-thinking\n",
            "google/gemini-2.5-flash-image\n",
            "qwen/qwen3-vl-30b-a3b-thinking\n",
            "qwen/qwen3-vl-30b-a3b-instruct\n",
            "openai/gpt-5-pro\n",
            "z-ai/glm-4.6\n",
            "z-ai/glm-4.6:exacto\n",
            "anthropic/claude-sonnet-4.5\n",
            "deepseek/deepseek-v3.2-exp\n",
            "thedrummer/cydonia-24b-v4.1\n",
            "relace/relace-apply-3\n",
            "google/gemini-2.5-flash-lite-preview-09-2025\n",
            "qwen/qwen3-vl-235b-a22b-thinking\n",
            "qwen/qwen3-vl-235b-a22b-instruct\n",
            "qwen/qwen3-max\n",
            "qwen/qwen3-coder-plus\n",
            "openai/gpt-5-codex\n",
            "deepseek/deepseek-v3.1-terminus:exacto\n",
            "deepseek/deepseek-v3.1-terminus\n",
            "x-ai/grok-4-fast\n",
            "alibaba/tongyi-deepresearch-30b-a3b\n",
            "qwen/qwen3-coder-flash\n",
            "opengvlab/internvl3-78b\n",
            "qwen/qwen3-next-80b-a3b-thinking\n",
            "qwen/qwen3-next-80b-a3b-instruct:free\n",
            "qwen/qwen3-next-80b-a3b-instruct\n",
            "meituan/longcat-flash-chat\n",
            "qwen/qwen-plus-2025-07-28\n",
            "qwen/qwen-plus-2025-07-28:thinking\n",
            "nvidia/nemotron-nano-9b-v2:free\n",
            "nvidia/nemotron-nano-9b-v2\n",
            "moonshotai/kimi-k2-0905\n",
            "moonshotai/kimi-k2-0905:exacto\n",
            "qwen/qwen3-30b-a3b-thinking-2507\n",
            "x-ai/grok-code-fast-1\n",
            "nousresearch/hermes-4-70b\n",
            "nousresearch/hermes-4-405b\n",
            "deepseek/deepseek-chat-v3.1\n",
            "openai/gpt-4o-audio-preview\n",
            "mistralai/mistral-medium-3.1\n",
            "baidu/ernie-4.5-21b-a3b\n",
            "baidu/ernie-4.5-vl-28b-a3b\n",
            "z-ai/glm-4.5v\n",
            "ai21/jamba-large-1.7\n",
            "openai/gpt-5-chat\n",
            "openai/gpt-5\n",
            "openai/gpt-5-mini\n",
            "openai/gpt-5-nano\n",
            "openai/gpt-oss-120b:free\n",
            "openai/gpt-oss-120b\n",
            "openai/gpt-oss-120b:exacto\n",
            "openai/gpt-oss-20b:free\n",
            "openai/gpt-oss-20b\n",
            "anthropic/claude-opus-4.1\n",
            "mistralai/codestral-2508\n",
            "qwen/qwen3-coder-30b-a3b-instruct\n",
            "qwen/qwen3-30b-a3b-instruct-2507\n",
            "z-ai/glm-4.5\n",
            "z-ai/glm-4.5-air:free\n",
            "z-ai/glm-4.5-air\n",
            "qwen/qwen3-235b-a22b-thinking-2507\n",
            "z-ai/glm-4-32b\n",
            "qwen/qwen3-coder:free\n",
            "qwen/qwen3-coder\n",
            "qwen/qwen3-coder:exacto\n",
            "bytedance/ui-tars-1.5-7b\n",
            "google/gemini-2.5-flash-lite\n",
            "qwen/qwen3-235b-a22b-2507\n",
            "switchpoint/router\n",
            "moonshotai/kimi-k2\n",
            "mistralai/devstral-medium\n",
            "mistralai/devstral-small\n",
            "cognitivecomputations/dolphin-mistral-24b-venice-edition:free\n",
            "x-ai/grok-4\n",
            "google/gemma-3n-e2b-it:free\n",
            "tencent/hunyuan-a13b-instruct\n",
            "tngtech/deepseek-r1t2-chimera\n",
            "morph/morph-v3-large\n",
            "morph/morph-v3-fast\n",
            "baidu/ernie-4.5-vl-424b-a47b\n",
            "baidu/ernie-4.5-300b-a47b\n",
            "inception/mercury\n",
            "mistralai/mistral-small-3.2-24b-instruct\n",
            "minimax/minimax-m1\n",
            "google/gemini-2.5-flash\n",
            "google/gemini-2.5-pro\n",
            "openai/o3-pro\n",
            "x-ai/grok-3-mini\n",
            "x-ai/grok-3\n",
            "google/gemini-2.5-pro-preview\n",
            "deepseek/deepseek-r1-0528:free\n",
            "deepseek/deepseek-r1-0528\n",
            "anthropic/claude-opus-4\n",
            "anthropic/claude-sonnet-4\n",
            "google/gemma-3n-e4b-it:free\n",
            "google/gemma-3n-e4b-it\n",
            "mistralai/mistral-medium-3\n",
            "google/gemini-2.5-pro-preview-05-06\n",
            "arcee-ai/spotlight\n",
            "arcee-ai/maestro-reasoning\n",
            "arcee-ai/virtuoso-large\n",
            "arcee-ai/coder-large\n",
            "inception/mercury-coder\n",
            "qwen/qwen3-4b:free\n",
            "meta-llama/llama-guard-4-12b\n",
            "qwen/qwen3-30b-a3b\n",
            "qwen/qwen3-8b\n",
            "qwen/qwen3-14b\n",
            "qwen/qwen3-32b\n",
            "qwen/qwen3-235b-a22b\n",
            "openai/o4-mini-high\n",
            "openai/o3\n",
            "openai/o4-mini\n",
            "qwen/qwen2.5-coder-7b-instruct\n",
            "openai/gpt-4.1\n",
            "openai/gpt-4.1-mini\n",
            "openai/gpt-4.1-nano\n",
            "eleutherai/llemma_7b\n",
            "alfredpros/codellama-7b-instruct-solidity\n",
            "x-ai/grok-3-mini-beta\n",
            "x-ai/grok-3-beta\n",
            "nvidia/llama-3.1-nemotron-ultra-253b-v1\n",
            "meta-llama/llama-4-maverick\n",
            "meta-llama/llama-4-scout\n",
            "qwen/qwen2.5-vl-32b-instruct\n",
            "deepseek/deepseek-chat-v3-0324\n",
            "openai/o1-pro\n",
            "mistralai/mistral-small-3.1-24b-instruct:free\n",
            "mistralai/mistral-small-3.1-24b-instruct\n",
            "allenai/olmo-2-0325-32b-instruct\n",
            "google/gemma-3-4b-it:free\n",
            "google/gemma-3-4b-it\n",
            "google/gemma-3-12b-it:free\n",
            "google/gemma-3-12b-it\n",
            "cohere/command-a\n",
            "openai/gpt-4o-mini-search-preview\n",
            "openai/gpt-4o-search-preview\n",
            "google/gemma-3-27b-it:free\n",
            "google/gemma-3-27b-it\n",
            "thedrummer/skyfall-36b-v2\n",
            "perplexity/sonar-reasoning-pro\n",
            "perplexity/sonar-pro\n",
            "perplexity/sonar-deep-research\n",
            "qwen/qwq-32b\n",
            "google/gemini-2.0-flash-lite-001\n",
            "anthropic/claude-3.7-sonnet\n",
            "anthropic/claude-3.7-sonnet:thinking\n",
            "mistralai/mistral-saba\n",
            "meta-llama/llama-guard-3-8b\n",
            "openai/o3-mini-high\n",
            "google/gemini-2.0-flash-001\n",
            "qwen/qwen-vl-plus\n",
            "aion-labs/aion-1.0\n",
            "aion-labs/aion-1.0-mini\n",
            "aion-labs/aion-rp-llama-3.1-8b\n",
            "qwen/qwen-vl-max\n",
            "qwen/qwen-turbo\n",
            "qwen/qwen2.5-vl-72b-instruct\n",
            "qwen/qwen-plus\n",
            "qwen/qwen-max\n",
            "openai/o3-mini\n",
            "mistralai/mistral-small-24b-instruct-2501\n",
            "deepseek/deepseek-r1-distill-qwen-32b\n",
            "perplexity/sonar\n",
            "deepseek/deepseek-r1-distill-llama-70b\n",
            "deepseek/deepseek-r1\n",
            "minimax/minimax-01\n",
            "microsoft/phi-4\n",
            "sao10k/l3.1-70b-hanami-x1\n",
            "deepseek/deepseek-chat\n",
            "sao10k/l3.3-euryale-70b\n",
            "openai/o1\n",
            "cohere/command-r7b-12-2024\n",
            "meta-llama/llama-3.3-70b-instruct:free\n",
            "meta-llama/llama-3.3-70b-instruct\n",
            "amazon/nova-lite-v1\n",
            "amazon/nova-micro-v1\n",
            "amazon/nova-pro-v1\n",
            "openai/gpt-4o-2024-11-20\n",
            "mistralai/mistral-large-2411\n",
            "mistralai/mistral-large-2407\n",
            "mistralai/pixtral-large-2411\n",
            "qwen/qwen-2.5-coder-32b-instruct\n",
            "raifle/sorcererlm-8x22b\n",
            "thedrummer/unslopnemo-12b\n",
            "anthropic/claude-3.5-haiku\n",
            "anthracite-org/magnum-v4-72b\n",
            "anthropic/claude-3.5-sonnet\n",
            "qwen/qwen-2.5-7b-instruct\n",
            "nvidia/llama-3.1-nemotron-70b-instruct\n",
            "inflection/inflection-3-pi\n",
            "inflection/inflection-3-productivity\n",
            "thedrummer/rocinante-12b\n",
            "meta-llama/llama-3.2-3b-instruct:free\n",
            "meta-llama/llama-3.2-3b-instruct\n",
            "meta-llama/llama-3.2-1b-instruct\n",
            "meta-llama/llama-3.2-11b-vision-instruct\n",
            "qwen/qwen-2.5-72b-instruct\n",
            "neversleep/llama-3.1-lumimaid-8b\n",
            "cohere/command-r-08-2024\n",
            "cohere/command-r-plus-08-2024\n",
            "sao10k/l3.1-euryale-70b\n",
            "qwen/qwen-2.5-vl-7b-instruct\n",
            "nousresearch/hermes-3-llama-3.1-70b\n",
            "nousresearch/hermes-3-llama-3.1-405b:free\n",
            "nousresearch/hermes-3-llama-3.1-405b\n",
            "sao10k/l3-lunaris-8b\n",
            "openai/gpt-4o-2024-08-06\n",
            "meta-llama/llama-3.1-405b\n",
            "meta-llama/llama-3.1-8b-instruct\n",
            "meta-llama/llama-3.1-405b-instruct\n",
            "meta-llama/llama-3.1-70b-instruct\n",
            "mistralai/mistral-nemo\n",
            "openai/gpt-4o-mini-2024-07-18\n",
            "openai/gpt-4o-mini\n",
            "google/gemma-2-27b-it\n",
            "google/gemma-2-9b-it\n",
            "sao10k/l3-euryale-70b\n",
            "nousresearch/hermes-2-pro-llama-3-8b\n",
            "mistralai/mistral-7b-instruct\n",
            "mistralai/mistral-7b-instruct-v0.3\n",
            "meta-llama/llama-guard-2-8b\n",
            "openai/gpt-4o-2024-05-13\n",
            "openai/gpt-4o\n",
            "openai/gpt-4o:extended\n",
            "meta-llama/llama-3-70b-instruct\n",
            "meta-llama/llama-3-8b-instruct\n",
            "mistralai/mixtral-8x22b-instruct\n",
            "microsoft/wizardlm-2-8x22b\n",
            "openai/gpt-4-turbo\n",
            "anthropic/claude-3-haiku\n",
            "mistralai/mistral-large\n",
            "openai/gpt-3.5-turbo-0613\n",
            "openai/gpt-4-turbo-preview\n",
            "mistralai/mistral-7b-instruct-v0.2\n",
            "mistralai/mixtral-8x7b-instruct\n",
            "neversleep/noromaid-20b\n",
            "alpindale/goliath-120b\n",
            "openrouter/auto\n",
            "openai/gpt-4-1106-preview\n",
            "openai/gpt-3.5-turbo-instruct\n",
            "mistralai/mistral-7b-instruct-v0.1\n",
            "openai/gpt-3.5-turbo-16k\n",
            "mancer/weaver\n",
            "undi95/remm-slerp-l2-13b\n",
            "gryphe/mythomax-l2-13b\n",
            "openai/gpt-4-0314\n",
            "openai/gpt-4\n",
            "openai/gpt-3.5-turbo\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str) -> CodeExplanation | None:\n",
        "    response = client.responses.parse(\n",
        "        model=DATAGEN_MODEL,\n",
        "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=TEMPERATURE,\n",
        "        stream=False,\n",
        "        text_format=CodeExplanation\n",
        "    )\n",
        "\n",
        "    return response.output_parsed\n",
        "\n",
        "def create_conversation(topic: str, code_length: str) -> CodeExplanation | None:\n",
        "    request = \"\"\n",
        "    if code_length == \"short\":\n",
        "        request = f\"2 - 4 lines of Python code about {topic}\"\n",
        "    elif code_length == \"paragraph\":\n",
        "        request = f\"3 - 6 lines of Python code about {topic}\"\n",
        "    elif code_length == \"small_function\":\n",
        "        request = f\"a small function (around 10 lines of Python code) about {topic}\"\n",
        "    elif code_length == \"large_function\":\n",
        "        request = f\"a large function (around 10 - 20 lines of Python code) about {topic}\"\n",
        "    else:\n",
        "        request = f\"a Python code example about {topic}\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        Generate me {request}.\n",
        "\n",
        "        For this selection of code, generate a short 2 paragraph explanation of what the selected code does:\n",
        "        - The explanation should be suitable for a high school student learning Python.\n",
        "        - When it makes sense, the second paragraph of the explanation should use an analogy to help the student better understand the code.\n",
        "        - DO NOT wrap the code in a ```python block\n",
        "\n",
        "        Return the following:\n",
        "        1. The original code as a string.\n",
        "        2. Your explanation of what the selected code does as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_dataset(num_examples: int, filename: str) -> None:\n",
        "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx in tqdm(range(num_examples)):\n",
        "      topic = random.choice(TOPICS)\n",
        "      code_length = random.choices(CODE_LENGTH, weights=CODE_LENGTH_WEIGHTS)[0]\n",
        "\n",
        "      conversation = None\n",
        "      while conversation == None:\n",
        "        conversation = create_conversation(topic, code_length)\n",
        "        if conversation == None:\n",
        "          print(f\"Error generating conversation for example {idx}\")\n",
        "\n",
        "      template = {\n",
        "          \"messages\": [\n",
        "              {\"role\": \"user\", \"content\": conversation.code},\n",
        "              {\n",
        "                  \"role\": \"assistant\",\n",
        "                  \"content\": conversation.explanation,\n",
        "              },\n",
        "          ]\n",
        "      }\n",
        "      line = json.dumps(template) + \"\\n\"\n",
        "      f.write(line)\n",
        "      f.flush()\n",
        "\n",
        "    f.flush()\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc06c35",
        "outputId": "9d71b479-ca36-4747-c957-dbf9d325ed80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:37<00:00,  3.79s/it]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "\n",
        "generate_dataset(10, TRAIN_FILE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}