{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# Generate Synthetic Training Data\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN_EXAMPLES = 8000  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 1000  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 100 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5.2-codex\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "TOPICS = [\n",
        "  \"Anti-air consistency (DP vs normal vs air-to-air)\",\n",
        "  \"Whiff punishing basics\",\n",
        "  \"Hit-confirming lights into special\",\n",
        "  \"Strike/throw offense\",\n",
        "  \"Meaty timing after knockdown\",\n",
        "  \"Defense: blocking high/low + delay tech\",\n",
        "  \"Throw tech vs shimmy awareness\",\n",
        "  \"Drive Impact reactions and counters\",\n",
        "  \"Drive Rush pressure and checking DR\",\n",
        "  \"Corner control and corner escape\",\n",
        "  \"Meter management (Drive Gauge + Super)\",\n",
        "  \"Matchup basics vs shotos (Ryu/Ken/Luke)\",\n",
        "  \"Matchup basics vs grapplers (Gief/Manon)\",\n",
        "  \"Matchup basics vs zoners (Dhalsim/JP)\",\n",
        "  \"Neutral: spacing with pokes\",\n",
        "  \"Punish combos: light/medium/heavy starters\",\n",
        "  \"Mental stack + decision making\",\n",
        "]\n",
        "\n",
        "COACH_DEPTH = [\n",
        "    \"short\",\n",
        "    \"paragraph\",\n",
        "    \"small_function\",\n",
        "    \"large_function\",\n",
        "]\n",
        "COACH_DEPTH_WEIGHTS = [0.25, 0.25, 0.25, 0.25]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "class SF6CoachAnswer(BaseModel):\n",
        "    student_goal: str\n",
        "    situation_summary: str\n",
        "    diagnosis: List[str]              # what's going wrong\n",
        "    key_concepts: List[str]           # what to learn\n",
        "    gameplan: List[str]               # actionable plan\n",
        "    drills: List[str]                 # training mode drills\n",
        "    mistakes_to_avoid: List[str]\n",
        "    quick_cheatsheet: List[str]       # 1-liners\n",
        "    confidence_note: str              # supportive, short\n",
        "\n",
        "class SF6Conversation(BaseModel):\n",
        "    user: str\n",
        "    assistant: SF6CoachAnswer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "bc6fd261",
      "metadata": {
        "id": "bc6fd261"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str) -> SF6Conversation | None:\n",
        "    response = client.responses.parse(\n",
        "        model=DATAGEN_MODEL,\n",
        "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=TEMPERATURE,\n",
        "        stream=False,\n",
        "        text_format=SF6Conversation\n",
        "    )\n",
        "\n",
        "    return response.output_parsed\n",
        "\n",
        "def create_conversation(topic: str, code_length: str) -> SF6Conversation | None:\n",
        "    request = \"\"\n",
        "    if code_length == \"short\":\n",
        "        request = f\"2 - 4 lines of Python code about {topic}\"\n",
        "    elif code_length == \"paragraph\":\n",
        "        request = f\"3 - 6 lines of Python code about {topic}\"\n",
        "    elif code_length == \"small_function\":\n",
        "        request = f\"a small function (around 10 lines of Python code) about {topic}\"\n",
        "    elif code_length == \"large_function\":\n",
        "        request = f\"a large function (around 10 - 20 lines of Python code) about {topic}\"\n",
        "    else:\n",
        "        request = f\"a Python code example about {topic}\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a Street Fighter 6 coach.\n",
        "\n",
        "    Create ONE realistic coaching exchange about: {topic}.\n",
        "    Student rank: choose one of [Rookie, Iron, Bronze, Silver, Gold, Platinum, Diamond, Master].\n",
        "    Character: choose one of [Ryu, Ken, Luke, Juri, Chun-Li, Cammy, Zangief, Manon, Marisa, JP, Guile].\n",
        "\n",
        "    Return:\n",
        "    1) A realistic student message (1-4 sentences) describing a problem, goal, or match situation.\n",
        "    2) A coaching answer for a high school student:\n",
        "      - 3-6 bullet diagnosis points\n",
        "      - a simple gameplan (3-6 bullets)\n",
        "      - 2-5 drills for Training Mode\n",
        "      - 3 common mistakes to avoid\n",
        "      - end with one short encouraging line\n",
        "\n",
        "    Do NOT mention that you are generating data.\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_dataset(num_examples: int, filename: str) -> None:\n",
        "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx in tqdm(range(num_examples)):\n",
        "      topic = random.choice(TOPICS)\n",
        "      code_length = random.choices(COACH_DEPTH, weights=COACH_DEPTH_WEIGHTS)[0]\n",
        "\n",
        "      conversation = None\n",
        "      while conversation == None:\n",
        "        conversation = create_conversation(topic, code_length)\n",
        "        if conversation == None:\n",
        "          print(f\"Error generating conversation for example {idx}\")\n",
        "\n",
        "      template = {\n",
        "          \"messages\": [\n",
        "              {\"role\": \"user\", \"content\": conversation.code},\n",
        "              {\n",
        "                  \"role\": \"assistant\",\n",
        "                  \"content\": conversation.explanation,\n",
        "              },\n",
        "          ]\n",
        "      }\n",
        "      line = json.dumps(template) + \"\\n\"\n",
        "      f.write(line)\n",
        "      f.flush()\n",
        "\n",
        "    f.flush()\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc06c35",
        "outputId": "9d71b479-ca36-4747-c957-dbf9d325ed80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:37<00:00,  3.79s/it]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "\n",
        "generate_dataset(10, TRAIN_FILE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}