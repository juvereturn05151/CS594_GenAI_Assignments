{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# Generate Synthetic Training Data\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN_EXAMPLES = 500  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 100  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 10 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5-nano\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "TOPICS = [\n",
        "  \"Anti-air consistency (DP vs normal vs air-to-air)\",\n",
        "  \"Whiff punishing basics\",\n",
        "  \"Hit-confirming lights into special\",\n",
        "  \"Strike/throw offense\",\n",
        "  \"Meaty timing after knockdown\",\n",
        "  \"Defense: blocking high/low + delay tech\",\n",
        "  \"Throw tech vs shimmy awareness\",\n",
        "  \"Drive Impact reactions and counters\",\n",
        "  \"Drive Rush pressure and checking DR\",\n",
        "  \"Corner control and corner escape\",\n",
        "  \"Meter management (Drive Gauge + Super)\",\n",
        "  \"Matchup basics vs shotos (Ryu/Ken/Luke/Sagat)\",\n",
        "  \"Matchup basics vs grapplers (Gief/Manon/Lily)\",\n",
        "  \"Matchup basics vs rush-down/mix-ups (Kimberly/Jamie/Elena)\",\n",
        "  \"Matchup basics vs zoners (Dhalsim/JP)\",\n",
        "  \"Matchup basics vs charged characters (Honda/Blanka/Bison/Guile/Deejay)\",\n",
        "  \"Neutral: spacing with pokes\",\n",
        "  \"Punish combos: light/medium/heavy starters\",\n",
        "  \"Mental stack + decision making\",\n",
        "]\n",
        "\n",
        "PLAYER_RANK = [\n",
        "    [\"Rookie\", \"Iron\", \"Bronze\", \"Silver\", \"Gold\"],\n",
        "    [\"Platinum\", \"Diamond\"],\n",
        "    [\"1300MR\", \"1400MR\"],\n",
        "    [\"1500MR\", \"1600MR\", \"1700MR\", \"1800MR\"],\n",
        "]\n",
        "\n",
        "PLAYER_RANK_WEIGHTS = [0.25, 0.25, 0.25, 0.25]\n",
        "\n",
        "CHARACTERS = [\n",
        "    \"Ryu\", \"Ken\", \"Luke\", \"Juri\", \"Chun-Li\", \"Cammy\",\n",
        "    \"Zangief\", \"Manon\", \"Marisa\", \"JP\", \"Guile\",\n",
        "    \"Ed\", \"Dhalsim\", \"Lily\", \"Rashid\", \"Terry\", \"Mai\",\n",
        "    \"Sagat\", \"Elena\", \"Honda\", \"Kimberly\",\n",
        "    \"AKI\", \"Bison\", \"Akuma\", \"Deejay\", \"Jamie\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "class SF6CoachAnswer(BaseModel):\n",
        "    student_goal: str\n",
        "    situation_summary: str\n",
        "    diagnosis: List[str]              # what's going wrong\n",
        "    key_concepts: List[str]           # what to learn\n",
        "    gameplan: List[str]               # actionable plan\n",
        "    drills: List[str]                 # training mode drills\n",
        "    mistakes_to_avoid: List[str]\n",
        "    quick_cheatsheet: List[str]       # 1-liners\n",
        "    confidence_note: str              # supportive, short\n",
        "\n",
        "class SF6Conversation(BaseModel):\n",
        "    user: str\n",
        "    assistant: SF6CoachAnswer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bc6fd261",
      "metadata": {
        "id": "bc6fd261"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str) -> SF6Conversation | None:\n",
        "    response = client.responses.parse(\n",
        "        model=DATAGEN_MODEL,\n",
        "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=TEMPERATURE,\n",
        "        stream=False,\n",
        "        text_format=SF6Conversation\n",
        "    )\n",
        "\n",
        "    return response.output_parsed\n",
        "\n",
        "def create_conversation(\n",
        "    topic: str,\n",
        "    player_rank: str,\n",
        "    player_character: str,\n",
        "    opponent_character: str\n",
        ") -> SF6Conversation | None:\n",
        "\n",
        "    opp = (opponent_character or \"\").strip()\n",
        "    has_matchup = bool(opp) and opp.lower() not in {\n",
        "        \"any\", \"unknown\", \"n/a\", \"na\", \"none\", \"random\", \"all\", \"everyone\", \"?\", \"tbd\"\n",
        "    }\n",
        "\n",
        "    matchup_rule = (\n",
        "        \"- Advice MUST reflect matchup specifics against the provided opponent.\\n\"\n",
        "        if has_matchup\n",
        "        else \"- If opponent character is missing/unknown, give universal SF6 advice for the topic (not matchup-specific).\\n\"\n",
        "             \"  - You MAY mention 1 bullet that asks who the opponent is, but still provide complete actionable guidance.\\n\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a Street Fighter 6 coach.\n",
        "\n",
        "    Topic: {topic}\n",
        "    Student rank: {player_rank}\n",
        "    Student character: {player_character}\n",
        "    Opponent character: {opp if opp else \"unknown\"}\n",
        "\n",
        "    Important rules:\n",
        "    {matchup_rule}- Advice level MUST match the student rank.\n",
        "      - Lower ranks → fundamentals, simple concepts.\n",
        "      - Master MR → advanced spacing traps, conditioning, frame traps, option coverage, mental stack.\n",
        "\n",
        "    Return ONLY valid JSON matching this schema exactly:\n",
        "\n",
        "    {{\n",
        "      \"user\": \"1-4 sentence realistic student message written from the player's perspective\",\n",
        "      \"assistant\": {{\n",
        "        \"diagnosis\": [\"3-6 bullet strings\"],\n",
        "        \"gameplan\": [\"3-6 bullet strings\"],\n",
        "        \"drills\": [\"2-5 bullet strings\"],\n",
        "        \"mistakes_to_avoid\": [\"exactly 3 bullet strings\"],\n",
        "        \"encouraging_line\": \"one short sentence\"\n",
        "      }}\n",
        "    }}\n",
        "\n",
        "    Do not wrap in code fences.\n",
        "    Do not add extra keys.\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_dataset_files(num_examples: int, jsonl_path: str, pretty_json_path: str) -> None:\n",
        "    examples = []\n",
        "\n",
        "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
        "        for idx in tqdm(range(num_examples)):\n",
        "\n",
        "            topic = random.choice(TOPICS)\n",
        "\n",
        "            # Rank selection\n",
        "            rank_bucket = random.choices(\n",
        "                PLAYER_RANK,\n",
        "                weights=PLAYER_RANK_WEIGHTS\n",
        "            )[0]\n",
        "            player_rank = random.choice(rank_bucket)\n",
        "\n",
        "            # Player character\n",
        "            player_character = random.choice(CHARACTERS)\n",
        "\n",
        "            # Opponent character (avoid mirror unless desired)\n",
        "            opponent_character = random.choice(\n",
        "                [c for c in CHARACTERS if c != player_character]\n",
        "            )\n",
        "\n",
        "            conversation = None\n",
        "            tries = 0\n",
        "\n",
        "            while conversation is None and tries < 8:\n",
        "                conversation = create_conversation(\n",
        "                    topic,\n",
        "                    player_rank,\n",
        "                    player_character,\n",
        "                    opponent_character\n",
        "                )\n",
        "                tries += 1\n",
        "\n",
        "            if conversation is None:\n",
        "                print(f\"Failed generating example {idx}\")\n",
        "                continue\n",
        "\n",
        "            record = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": conversation.user},\n",
        "                    {\"role\": \"assistant\", \"content\": conversation.assistant.model_dump()},\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            f_jsonl.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "            examples.append(record)\n",
        "\n",
        "    with open(pretty_json_path, \"w\", encoding=\"utf-8\") as f_pretty:\n",
        "        json.dump(examples, f_pretty, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4fc06c35",
        "outputId": "a4d08d03-8e3b-44f1-b9b3-a22c9673e806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [8:02:27<00:00, 48.25s/it]\n",
            "100%|██████████| 100/100 [1:32:06<00:00, 55.27s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "generate_dataset_files() missing 1 required positional argument: 'pretty_json_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1484871344.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgenerate_dataset_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TRAIN_EXAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pretty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgenerate_dataset_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_VAL_EXAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pretty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgenerate_dataset_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TEST_EXAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pretty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: generate_dataset_files() missing 1 required positional argument: 'pretty_json_path'"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "train_pretty = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.pretty.json\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "valid_pretty = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.pretty.json\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "test_pretty = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "\n",
        "generate_dataset_files(NUM_TRAIN_EXAMPLES, TRAIN_FILE, train_pretty)\n",
        "generate_dataset_files(NUM_VAL_EXAMPLES, VALID_FILE, valid_pretty)\n",
        "generate_dataset_files(NUM_TEST_EXAMPLES, TEST_FILE, test_pretty)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}