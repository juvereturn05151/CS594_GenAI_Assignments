{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# BibleAssistant\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Literal, Optional, Dict, Any, Tuple\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 1000  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 100  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 10 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5-nano\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "BIBLE_BOOKS = [\n",
        "    \"Old Testament\",\n",
        "    \"New Testament\",\n",
        "]\n",
        "\n",
        "ISSUE_QUESTIONS_CATEGORIES = [\n",
        "    \"anxiety\", \"fear\", \"grief\", \"guilt\", \"anger\", \"loneliness\",\n",
        "    \"guidance\", \"forgiveness\", \"burnout\", \"temptation\", \"question\"\n",
        "]\n",
        "\n",
        "SEVERITY_LEVELS = [\"mild\", \"moderate\", \"severe\", \"crisis\"]\n",
        "\n",
        "# How often we generate each severity (crisis is rarer)\n",
        "SEVERITY_WEIGHTS = [0.35, 0.35, 0.22, 0.08]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "class BibleExplanation(BaseModel):\n",
        "    issue_question: str\n",
        "    verse: str\n",
        "    explanation: str\n",
        "    guidance: List[str] = Field(default_factory=list)\n",
        "    note: str\n",
        "\n",
        "class BibleConversation(BaseModel):\n",
        "    user: str\n",
        "    assistant: BibleExplanation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bc6fd261",
      "metadata": {
        "id": "bc6fd261"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str) -> Optional[BibleConversation]:\n",
        "    try:\n",
        "        response = client.responses.parse(\n",
        "            model=DATAGEN_MODEL,\n",
        "            input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=TEMPERATURE,\n",
        "            stream=False,\n",
        "            text_format=BibleConversation,\n",
        "        )\n",
        "        return response.output_parsed\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def create_conversation(issue_question: str, severity: str) -> Optional[BibleConversation]:\n",
        "\n",
        "    if(issue_question == \"question\"):\n",
        "      request = f\"Provide a  Bible verse about {issue_question}, and explain the mearning.\"\n",
        "    else:\n",
        "      if severity == \"mild\":\n",
        "          request = f\"Provide a  Bible verse about {issue_question}, with brief encouragement (1–2 sentences each).\"\n",
        "      elif severity == \"moderate\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, each with short meaning explanations and 3–4 practical guidance steps.\"\n",
        "      elif severity == \"severe\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with deeper explanations and 4–6 compassionate guidance steps. Include strong reassurance.\"\n",
        "      elif severity == \"crisis\":\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with careful, supportive explanations. Include clear encouragement to seek immediate help from trusted people or local emergency services if the person is in danger.\"\n",
        "      else:\n",
        "          request = f\"Provide a Bible verse about {issue_question}, with short explanations and practical encouragement.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Create a realistic conversation from {request}.\n",
        "\n",
        "    Context:\n",
        "    - Topic: {issue_question}\n",
        "    - Severity: {severity}\n",
        "\n",
        "    Rules:\n",
        "    - Use ONLY books from this list:\n",
        "    {\", \".join(BIBLE_BOOKS)}\n",
        "    - Verse references must be: \"Book Chapter:Verse\" or \"Book Chapter:Verse-Verse\"\n",
        "    - Do NOT cite any book outside the allowed list\n",
        "\n",
        "    Return the following if {issue_question} is \"question\":\n",
        "    1. 1–3 sentences written as the user describing their situation about {issue_question} in your own word as a string.\n",
        "    2. The single Bible selected verse and its content as a single string.\n",
        "    3. One paragraphs in one string explaining how the verses address the issue.\n",
        "\n",
        "    Return the following if {issue_question} is not \"question\":\n",
        "    1. 1–3 sentences written as the user describing their situation about {issue_question} in your own word as a string.\n",
        "    2. The single Bible selected verse and its content as a single string.\n",
        "    3. One paragraphs in one string explaining how the verses address the issue.\n",
        "    4. 1–6 short practical action steps\n",
        "    5. Short compassionate closing note. If severity is crisis, encourage contacting trusted people or emergency services.\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def generate_dataset_files(num_examples: int, jsonl_path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(jsonl_path), exist_ok=True)\n",
        "\n",
        "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
        "        for idx in tqdm(range(num_examples)):\n",
        "            issue = random.choice(ISSUE_QUESTIONS_CATEGORIES)\n",
        "            severity = random.choices(SEVERITY_LEVELS, weights=SEVERITY_WEIGHTS)[0]\n",
        "\n",
        "            conv = None\n",
        "            tries = 0\n",
        "            while conv is None and tries < 6:\n",
        "                conv = create_conversation(issue, severity)\n",
        "                tries += 1\n",
        "\n",
        "            if conv is None:\n",
        "                print(f\"Error generating conversation for example {idx}\")\n",
        "                continue\n",
        "\n",
        "            template = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": conv.user},\n",
        "                    {\n",
        "                        \"role\": \"assistant\",\n",
        "                        \"content\": json.dumps(conv.assistant.model_dump(), ensure_ascii=False),\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            f_jsonl.write(json.dumps(template, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc06c35",
        "outputId": "76a5b11a-3f04-44c5-c817-2730eeb6cfb2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 232/1000 [4:03:24<25:51:19, 121.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 331/1000 [5:33:15<20:46:49, 111.82s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 330\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 379/1000 [6:19:47<18:45:34, 108.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 378\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 437/1000 [7:12:24<15:44:21, 100.64s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating conversation for example 436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [15:02:54<00:00, 54.17s/it]\n",
            " 95%|█████████▌| 95/100 [1:19:36<10:00, 120.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating conversation for example 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [1:24:00<00:00, 50.40s/it]\n",
            "100%|██████████| 10/10 [08:09<00:00, 48.98s/it]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "\n",
        "generate_dataset_files(NUM_TRAIN_EXAMPLES, TRAIN_FILE)\n",
        "generate_dataset_files(NUM_VAL_EXAMPLES, VALID_FILE)\n",
        "generate_dataset_files(NUM_TEST_EXAMPLES, TEST_FILE)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}