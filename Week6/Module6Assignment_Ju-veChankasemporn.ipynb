{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d4aa350",
      "metadata": {
        "id": "3d4aa350"
      },
      "source": [
        "# BibleEncouragementAssistant\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/06/notebooks/generate-synthetic.ipynb\">\n",
        "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5572879c",
      "metadata": {
        "id": "5572879c"
      },
      "source": [
        "## Data generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29c9393",
      "metadata": {
        "id": "d29c9393"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Literal, Optional, Dict, Any, Tuple\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 500  # @param {type:\"number\"}\n",
        "NUM_VAL_EXAMPLES = 100  # @param {type:\"number\"}\n",
        "NUM_TEST_EXAMPLES = 10 # @param {type:\"number\"}\n",
        "TEMPERATURE = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "DATA_FOLDER = \"./.data/generated\"\n",
        "!mkdir -p {DATA_FOLDER}\n",
        "\n",
        "DATAGEN_MODEL = \"openai/gpt-5-nano\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c9b3d",
      "metadata": {
        "id": "672c9b3d"
      },
      "source": [
        "## Dataset diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a485a8de",
      "metadata": {
        "id": "a485a8de"
      },
      "outputs": [],
      "source": [
        "BIBLE_BOOKS_CHAPTERS = [\n",
        "    # Old Testament\n",
        "    \"Genesis\", \"Exodus\", \"Leviticus\", \"Numbers\", \"Deuteronomy\",\n",
        "    \"Joshua\", \"Judges\", \"Ruth\",\n",
        "    \"1 Samuel\", \"2 Samuel\",\n",
        "    \"1 Kings\", \"2 Kings\",\n",
        "    \"1 Chronicles\", \"2 Chronicles\",\n",
        "    \"Ezra\", \"Nehemiah\", \"Esther\",\n",
        "    \"Job\", \"Psalm\", \"Proverbs\",\n",
        "    \"Ecclesiastes\", \"Song of Solomon\",\n",
        "    \"Isaiah\", \"Jeremiah\", \"Lamentations\",\n",
        "    \"Ezekiel\", \"Daniel\",\n",
        "    \"Hosea\", \"Joel\", \"Amos\",\n",
        "    \"Obadiah\", \"Jonah\", \"Micah\",\n",
        "    \"Nahum\", \"Habakkuk\", \"Zephaniah\",\n",
        "    \"Haggai\", \"Zechariah\", \"Malachi\",\n",
        "\n",
        "    # New Testament\n",
        "    \"Matthew\", \"Mark\", \"Luke\", \"John\",\n",
        "    \"Acts\", \"Romans\",\n",
        "    \"1 Corinthians\", \"2 Corinthians\",\n",
        "    \"Galatians\", \"Ephesians\", \"Philippians\", \"Colossians\",\n",
        "    \"1 Thessalonians\", \"2 Thessalonians\",\n",
        "    \"1 Timothy\", \"2 Timothy\",\n",
        "    \"Titus\", \"Philemon\",\n",
        "    \"Hebrews\", \"James\",\n",
        "    \"1 Peter\", \"2 Peter\",\n",
        "    \"1 John\", \"2 John\", \"3 John\",\n",
        "    \"Jude\", \"Revelation\",\n",
        "]\n",
        "\n",
        "ISSUE_CATEGORIES = [\n",
        "    \"anxiety\", \"fear\", \"grief\", \"guilt\", \"anger\", \"loneliness\",\n",
        "    \"guidance\", \"forgiveness\", \"burnout\", \"temptation\"\n",
        "]\n",
        "\n",
        "SEVERITY_LEVELS = [\"mild\", \"moderate\", \"severe\", \"crisis\"]\n",
        "\n",
        "# How often we generate each severity (crisis is rarer)\n",
        "SEVERITY_WEIGHTS = [0.35, 0.35, 0.22, 0.08]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421c49e4",
      "metadata": {
        "id": "421c49e4"
      },
      "source": [
        "## Model for structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91787f37",
      "metadata": {
        "id": "91787f37"
      },
      "outputs": [],
      "source": [
        "class BibleExplanation(BaseModel):\n",
        "    chapter: str\n",
        "    verse: str\n",
        "    explanation: str"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "712a3900",
      "metadata": {
        "id": "712a3900"
      },
      "source": [
        "## Get OpenRouter API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6fd261",
      "metadata": {
        "id": "bc6fd261"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import userdata # type:ignore\n",
        "  os.environ['OPENROUTER_API_KEY'] = userdata.get('OpenRouter')\n",
        "else:\n",
        "  load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218aa9db",
      "metadata": {
        "id": "218aa9db"
      },
      "source": [
        "## Conversation generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce9bb29",
      "metadata": {
        "id": "1ce9bb29"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        ")\n",
        "\n",
        "def generate_completion(prompt: str):\n",
        "    try:\n",
        "        response = client.responses.parse(\n",
        "            model=DATAGEN_MODEL,\n",
        "            input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=TEMPERATURE,\n",
        "            stream=False,\n",
        "            text_format=BibleExplanation\n",
        "        )\n",
        "        return response.output_parsed\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def create_conversation(issue: str, severity: str) -> BibleExplanation | None:\n",
        "    request = \"\"\n",
        "    if severity == \"mild\":\n",
        "        request = (\n",
        "        f\"Provide 2–3 short Bible verse references from {BIBLE_BOOKS_CHAPTERS} \"\n",
        "        f\"about {issue}, with brief encouragement (1–2 sentences each).\"\n",
        "    )\n",
        "\n",
        "    elif severity == \"moderate\":\n",
        "        request = (\n",
        "        f\"Provide 3–5 Bible verse references from {BIBLE_BOOKS_CHAPTERS} \"\n",
        "        f\"about {issue}, each with short meaning explanations and \"\n",
        "        f\"3–4 practical guidance steps.\"\n",
        "    )\n",
        "    elif severity == \"severe\":\n",
        "        request = (\n",
        "        f\"Provide 4–6 Bible verse references from {BIBLE_BOOKS_CHAPTERS} \"\n",
        "        f\"about {issue}, with deeper explanations and 4–6 compassionate \"\n",
        "        f\"guidance steps. Include strong reassurance.\"\n",
        "    )\n",
        "    elif severity == \"crisis\":\n",
        "        request = (\n",
        "        f\"Provide 4–6 Bible verse references from {BIBLE_BOOKS_CHAPTERS}\"\n",
        "        f\"about {issue}, with careful, supportive explanations. \"\n",
        "        f\"Include clear encouragement to seek immediate help from trusted \"\n",
        "        f\"people or local emergency services if the person is in danger.\"\n",
        "    )\n",
        "\n",
        "    else:\n",
        "        request = (\n",
        "        f\"Provide Bible verse references from  {BIBLE_BOOKS_CHAPTERS} about {issue}, \"\n",
        "        f\"with short explanations and practical encouragement.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate {request}\n",
        "\n",
        "    Context:\n",
        "    - The user is sharing something related to: {issue}\n",
        "    - Severity level: {severity}\n",
        "\n",
        "    Rules:\n",
        "    - Use ONLY Bible verse references from the allowed books(old testament and new testament) and chapters list: {\", \".join(BIBLE_BOOKS_CHAPTERS)}\n",
        "    - Provide verse references in the format: \"Book Chapter:Verse\" or \"Book Chapter:Verse-Verse\"\n",
        "    - Do NOT cite any book outside the allowed list\n",
        "    - Do NOT include long direct quotes from the Bible (keep it paraphrased and explained)\n",
        "\n",
        "    For this selection of verses, write a short 2-paragraph explanation:\n",
        "    - The explanation should be suitable for a high school student (clear, simple language).\n",
        "    - When it makes sense, the second paragraph should use an analogy to help the person understand the message.\n",
        "    - Keep the tone compassionate and practical.\n",
        "\n",
        "    Return the following:\n",
        "    1) The selected verse references as a list of strings (NOT the verse text).\n",
        "    2) Your 2-paragraph explanation as a single string.\n",
        "    3) A practical guidance list (3–6 bullet strings) the user can do today.\n",
        "    4) A short note string (if severity is \"crisis\", encourage reaching out to trusted people or local emergency services).\n",
        "    \"\"\"\n",
        "\n",
        "    return generate_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fbaaf3",
      "metadata": {
        "id": "97fbaaf3"
      },
      "source": [
        "## Dataset generation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79b6bfc",
      "metadata": {
        "id": "e79b6bfc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_dataset_files(num_examples: int, jsonl_path: str, pretty_json_path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(jsonl_path), exist_ok=True)\n",
        "\n",
        "    examples = []\n",
        "\n",
        "    with open(jsonl_path, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
        "        for idx in tqdm(range(num_examples)):\n",
        "            issue = random.choice(ISSUE_CATEGORIES)\n",
        "            severity = random.choices(SEVERITY_LEVELS, weights=SEVERITY_WEIGHTS)[0]\n",
        "\n",
        "            conversation = None\n",
        "            tries = 0\n",
        "            while conversation is None and tries < 6:\n",
        "                conversation = create_conversation(issue, severity)\n",
        "                tries += 1\n",
        "\n",
        "            if conversation is None:\n",
        "                print(f\"Error generating conversation for example {idx}\")\n",
        "                continue\n",
        "\n",
        "            template = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": conversation[\"user\"]},\n",
        "                    {\"role\": \"assistant\", \"content\": json.dumps(conversation[\"assistant\"], ensure_ascii=False)},\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            f_jsonl.write(json.dumps(template, ensure_ascii=False) + \"\\n\")\n",
        "            f_jsonl.flush()\n",
        "            examples.append(template)\n",
        "\n",
        "    with open(pretty_json_path, \"w\", encoding=\"utf-8\") as f_pretty:\n",
        "        json.dump(examples, f_pretty, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98fa54d",
      "metadata": {
        "id": "d98fa54d"
      },
      "source": [
        "## Generate all the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc06c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fc06c35",
        "outputId": "b2995429-1eef-4d24-c428-0ff6a15ec2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [05:26<00:00, 32.68s/it]\n",
            "100%|██████████| 10/10 [05:09<00:00, 30.99s/it]\n",
            "100%|██████████| 10/10 [05:35<00:00, 33.58s/it]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TRAIN_FILE = f\"{DATA_FOLDER}/train_pretty_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "train_pretty = f\"{DATA_FOLDER}/train_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.pretty.json\"\n",
        "VALID_FILE = f\"{DATA_FOLDER}/valid_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "valid_pretty = f\"{DATA_FOLDER}/valid_pretty_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.pretty.json\"\n",
        "TEST_FILE = f\"{DATA_FOLDER}/test_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.jsonl\"\n",
        "test_pretty = f\"{DATA_FOLDER}/test_pretty_{datetime.now().strftime('%Y-%m-%d-%H:%M:%S')}.pretty.json\"\n",
        "\n",
        "generate_dataset_files(NUM_TRAIN_EXAMPLES, TRAIN_FILE, train_pretty)\n",
        "generate_dataset_files(NUM_VAL_EXAMPLES, VALID_FILE, valid_pretty)\n",
        "generate_dataset_files(NUM_TEST_EXAMPLES, TEST_FILE, test_pretty)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}