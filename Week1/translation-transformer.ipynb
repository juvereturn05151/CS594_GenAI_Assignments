{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ebb72",
   "metadata": {},
   "source": [
    "# Translation Transformer\n",
    "\n",
    "In this notebook, we use a small transformer (Helsinki-NLP/opus-mt-fr-en) to translate from French to English.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/simonguest/CS-394/blob/main/src/01/notebooks/translation-transformer.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a target=\"_blank\" href=\"https://github.com/simonguest/CS-394/raw/refs/heads/main/src/01/notebooks/translation-transformer.ipynb\">\n",
    "  <img src=\"https://img.shields.io/badge/Download_.ipynb-blue\" alt=\"Download .ipynb\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deaee52",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T05:00:38.854706Z",
     "start_time": "2026-01-12T05:00:30.579739Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drago\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001B[0;32m      3\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHelsinki-NLP/opus-mt-fr-en\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSeq2SeqLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1180\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1178\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer_class_py\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1180\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1181\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1182\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min order to use this tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1183\u001B[0m             )\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1186\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to build an AutoTokenizer.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1187\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mTOKENIZER_MAPPING)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1188\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c2a1b892",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8703,    2, 1027, 5682,   21,  682,   54,    0])\n",
      "Tokens: ['▁Bonjour', ',', '▁comment', '▁allez', '-', 'vous', '?', '</s>']\n"
     ]
    }
   ],
   "source": [
    "french_text = \"Bonjour, comment allez-vous?\"\n",
    "input_ids = tokenizer.encode(french_text, return_tensors=\"pt\")\n",
    "print(input_ids[0])\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e89f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([1, 8, 512])\n",
      "Encoder output: BaseModelOutput(last_hidden_state=tensor([[[-0.3943,  0.4660,  0.0190,  ..., -0.5069,  0.2120, -0.3190],\n",
      "         [ 0.0957,  0.0780,  0.1918,  ..., -0.0854,  0.2138,  0.1528],\n",
      "         [-0.6160,  0.0295,  0.1918,  ..., -0.3886,  0.0770,  0.2311],\n",
      "         ...,\n",
      "         [-0.1839, -0.3798,  0.1832,  ..., -0.0041, -0.3633, -0.5455],\n",
      "         [ 0.0153,  0.0264,  0.1122,  ...,  0.1966, -0.3027, -0.3659],\n",
      "         [-0.0484,  0.0147,  0.0078,  ..., -0.1359, -0.0295, -0.0799]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# @title Demonstrate contextual vectors using the encoder\n",
    "\n",
    "# French: \"Bonjour , comment allez  - vous  ?\"\n",
    "#          ↓       ↓    ↓      ↓    ↓  ↓    ↓\n",
    "# Encoder: [v1]   [v2] [v3]  [v4] [v5][v6][v7]  ← 7 vectors, each 512-dim\n",
    "#          └─────────────────────────────────┘\n",
    "\n",
    "encoder = model.get_encoder()\n",
    "encoder_output = encoder(input_ids)\n",
    "print(\"Encoder output shape:\", encoder_output.last_hidden_state.shape)\n",
    "print(\"Encoder output:\", encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532519ba",
   "metadata": {},
   "source": [
    "## Run through tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transformer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[59513, 10537,     2,   541,    52,    55,    54,     0]])\n"
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(input_ids)\n",
    "print(output_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaa43e",
   "metadata": {},
   "source": [
    "## Decode back to tokens to complete the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "english_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Translation:\", english_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
